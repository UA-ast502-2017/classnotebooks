{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AST 502: Lecture 4: Maximum Likelihood Estimator\n",
    "\n",
    "## Ragadeepika Pucha, Fall 2017, Chapter 4.1-4.4\n",
    "\n",
    "A quick review of \n",
    "- Statistical Inference.\n",
    "- The Likelihood Function.\n",
    "- Maximum Likelihood Estimator.\n",
    "- MLE Applied to Homoscedastic and Heteroscedastic Gaussians.\n",
    "- The Goodness of Fit.\n",
    "- Expectation Maximization Algorithm.\n",
    "\n",
    "based on Ivezic book and UW Astr 324 Class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Statistical Inference -\n",
    "## Drawing Conclusions from the data\n",
    "\n",
    "There are three main types of inference -\n",
    "\n",
    "- **Point Estimation:** Based on the available data, what is the best estimate of a parameter?\n",
    "- **Confidence Estimation:** How confident are we about the point estimation?\n",
    "- **Hypothesis Testing:** Are the data consistent with a given hypothesis or model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Frequentist VS Bayesian Inference -\n",
    "\n",
    "### Frequentist -\n",
    "- _Classical_ approach - Probabilities refer to the relative frequencies of events.\n",
    "- Data varies\n",
    "- Parameters are fixed.\n",
    "\n",
    "### Bayesian -\n",
    "- Probability is the degree of subjective belief.\n",
    "- Depends on the set of initial conditions - known as _Priors_.\n",
    "- Data is fixed.\n",
    "- Inferences about the parameter are made by producing probability distributions of them. Estimates are then made based of these distributions.\n",
    "\n",
    "Interested Further Reading - http://www.behind-the-enemy-lines.com/2008/01/are-you-bayesian-or-frequentist-or.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Likelihood Function -\n",
    "\n",
    "This is a quantitative measurement of our measuring process - Probability of _data_ given a _model_.\n",
    "\n",
    "Assume a parent distribution $N (\\mu, \\sigma)$ from which our data $\\{x_i\\}$ are being drawn. The likelihood of a given value $x_i$ is just given by inputting the value in the probability distribution function. Assuming that the individual values are independent, the likelihood of the entire data (not just one measurement) is given by the likelihood function, $L$ - \n",
    "\n",
    "$$L = p(\\{x_i\\})|M(\\theta)) = \\prod_{i=1}^{n}p(x_i|M(\\theta))$$\n",
    "\n",
    "where $M(\\theta)$ stands for our model and $\\theta$ are the parameters for the model.\n",
    "\n",
    "For example, for the Gaussian distribution probability of getting a specific value of $x$ is given by:\n",
    "$$p(x|\\mu,\\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(\\frac{-(x-\\mu)^2}{2\\sigma^2}\\right)$$\n",
    "\n",
    "### Note:\n",
    "- Although L is the \"Probability of the data given the model\", it is not a true pdf - does not normalize to 1.\n",
    "- It can be a function of both the data as well as the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "This is relevant in both Bayesian and Frequentist approaches.\n",
    "\n",
    "### Maximum Likelihood Approach\n",
    "Maximum Likelihood estimation consists of the following steps:\n",
    "\n",
    "1. **Hypothesis:** Fomulate a model, a _hypothesis_, about how the data is generated. The resulting inferences are strongly dependent of the quality of this assumption. Models are typically descibed using a set of parameters $\\theta$, and written as $M(\\theta)$.\n",
    "\n",
    "2. **Maximum Likelihood Estimation:** Search for the best model parameters $\\theta$ which maximizes the likelihood $L(\\theta) = p(data|model)$. This search gives the MLE point estimates.\n",
    "\n",
    "3. **Estimate Uncertainty:** Determine the confidence region for the model parameters. It can be done analytically with some approximations, or numerically for arbitraty models using general frequentist techniques, such as bootstrap, jackknife, and cross-validation.\n",
    "\n",
    "4. **Hypothesis Testing:** Perform hypothesis tests as needed to make conclusions about the model and the point estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Measuring the Position of a Quasar\n",
    "_credits: UW ASTR324 Lectures_\n",
    "\n",
    "Let's assume we want to estimate the position $x$ of a quasar from a series of individual astrometric measurements.\n",
    "\n",
    "1. We adopt a model where the observed quasar does not move, and individual measurement errors are drawn from a normal distribution.\n",
    "\n",
    "2. We derive the expression for the likelihood of there being a quasar at position $x_{0}$ that gives rise to our individual measurements. We find the value of $x'_{0}$ for which the likelihood is maximum.\n",
    "\n",
    "3. Determine the error bars of our measurement.\n",
    "\n",
    "4. We test whether what we've observed is consistent with our adopted model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Back to the Likelihood Function\n",
    "\n",
    "The likelihood function, $L$ is - \n",
    "\n",
    "$$L = p(\\{x_i\\})|M(\\theta)) = \\prod_{i=1}^{n}p(x_i|M(\\theta))$$\n",
    "\n",
    "If the parent distribution is considered to be gaussian, then this can be written as - \n",
    "\n",
    "$$L = \\left( \\prod_{i=1}^n \\frac{1}{\\sigma\\sqrt{2\\pi}} \\right) \\exp\\left( -\\frac{1}{2} \\sum \\left[\\frac{(x_i-\\mu)}{\\sigma} \\right]^2 \\right)$$\n",
    "\n",
    "The exponential part is just \n",
    "\n",
    "$$\\exp \\left(-\\frac{\\chi^2}{2}\\right)$$ as,\n",
    "\n",
    "$$\\chi^2 = \\sum_{i=1}^n \\left ( \\frac{x_i-\\mu}{\\sigma}\\right)^2.$$\n",
    "\n",
    "So, maximizing the likelihood is the same as minimizing $\\chi^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Core Idea Behind Maximum Likelihood Estimators\n",
    "\n",
    "Let's say that we know that some data were drawn from a Gaussian distribution, but we don't know the $\\theta = (\\mu, \\sigma)$ values of that distribution. \n",
    "\n",
    "In such a case, the MLE tells us to think of the likelihood as a function of the unknown parameters that maximize the value of the function. Those will be our Maximum Likelihood Estimators for the true values of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MLE Applied to Homoscedastic Gaussian\n",
    "\n",
    "This just means that all the measurements have the same error, say $\\sigma$. If the measurements can have different errors, then its called _heteroscedastic_.\n",
    "\n",
    "For an experiment with the set of measured positions $D = \\{x_i\\}$ in one dimension with Guassian errors, the likelihood function is:\n",
    "\n",
    "$$L = p(\\{x_i\\})|M(\\theta))= \\left( \\prod_{i=1}^n \\frac{1}{\\sigma\\sqrt{2\\pi}} \\right) \\exp\\left( -\\frac{1}{2} \\sum \\left[\\frac{-(x_i-\\mu)}{\\sigma} \\right]^2 \\right)$$\n",
    "\n",
    "If $\\sigma$ is both constant and known, then there is only one parameter for the model, $\\theta = \\mu$.\n",
    "\n",
    "Taking log on both sides - \n",
    "\n",
    "$$\\ln L = constant - \\frac{1}{2}\\sum_{i=1}^{n} \\left[\\frac{(x_i-\\mu)^2}{\\sigma^2} \\right] $$\n",
    "\n",
    "If the estimate of $\\mu$ is $\\mu_{0}$ (say), then this can be found by maximizing the likelihood function.\n",
    "\n",
    "$$\\frac{d\\;{\\rm lnL}(\\mu)}{d\\mu}\\Biggr\\rvert_{\\mu_{0}} \\equiv 0$$\n",
    "\n",
    "That gives $$ \\sum_{i=1}^N \\frac{(x_i - \\mu_{0})}{\\sigma^2} = 0$$\n",
    "\n",
    "Since $\\sigma$ is a constant, we get - \n",
    "\n",
    "$$\\sum_{i=1}^N x_i = \\sum_{i=1}^N \\mu_{0} = N \\mu_{0}$$\n",
    "\n",
    "Thus we find that\n",
    "$$\\mu_{0} = \\frac{1}{N}\\sum_{i=1}^N x_i$$\n",
    "which is just the arithmetic mean of all the measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example\n",
    "\n",
    "Assume a Gaussian distribution with $\\mu$ = 5 and $\\sigma$ = 1. Lets simulate 10 measurements and comupte the MLE of $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x111b4dd90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqMAAAHiCAYAAADcc8U8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111781b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute this cell\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from astroML.plotting import setup_text_plots\n",
    "setup_text_plots(fontsize=15, usetex=False)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "np.random.seed(seed=42)\n",
    "Nsamples=1000                                                                # Make changes here\n",
    "measurements = np.random.normal(5, 1, Nsamples)\n",
    "mu = np.average(measurements)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# plot the distributions\n",
    "fig, ax = plt.subplots(figsize=(10, 7.5))\n",
    "dist = norm(mu, 1)\n",
    "dist_p = norm(5,1)\n",
    "C = (1./(2.*np.pi))**(10./2.)\n",
    "x = np.linspace(0, 10, 1000)\n",
    "plt.plot(x, C* dist.pdf(x), c='black',label=r'$\\mu_{0}=%.2f,\\ \\sigma=1$' % mu)\n",
    "plt.plot(x, C* dist_p.pdf(x), c = 'red', label=r'$\\mu = 5,\\ \\sigma = 1$')\n",
    "#plt.axvline(x=5)\n",
    "\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 0.5*C)\n",
    "\n",
    "plt.xlabel('$\\mu$')\n",
    "plt.ylabel(r'$L(\\{x\\}|\\mu,\\sigma=1)$')\n",
    "plt.title('Likelihood of $\\mu$')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quantifying Estimate Uncertainty\n",
    "\n",
    "The uncertainty on the MLEs are obtained by the second (partial) derivatives of the log-likelihood:\n",
    "\n",
    "$$\\sigma_{jk} = \\left( - \\frac{d^2}{d\\theta_j} \\frac{\\ln L}{d\\theta_k} \\Biggr\\rvert_{\\theta=\\theta_{0}}\\right)^{-1/2}$$\n",
    "\n",
    "For our estimate of $\\mu$,\n",
    "\n",
    "$$\\sigma_{\\mu} = \\left( - \\frac{d^2\\ln L(\\mu)}{d\\mu^2}\\Biggr\\rvert_{\\mu_{0}}\\right)^{-1/2}$$\n",
    "\n",
    "Solving - $$\\sigma_{\\mu} = \\frac{\\sigma}{\\sqrt{N}}.$$\n",
    "\n",
    "So, our estimator of $\\mu$ is $\\mu_{0} \\pm\\frac{\\sigma}{\\sqrt{N}}$ is our result. In other words $(\\mu_{0} - \\sigma_{\\mu}, \\mu_{0} + \\sigma_{\\mu})$ gives us our confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MLE Applied to a Heteroscedastic Gaussian:\n",
    "\n",
    "Now, we consider the measurements where the errors are different, but they are known. Since $\\sigma_{i}$ are not constant the equation of log-likelihood will be - \n",
    "\n",
    "$$\\ln L = {\\rm constant} - \\sum_{i=1}^N \\frac{(x_i - \\mu)^2}{2\\sigma_i^2}.$$\n",
    "\n",
    "Taking the derivative:\n",
    "$$\\frac{d\\;{\\rm \\ln L}(\\mu)}{d\\mu}\\Biggr\\rvert_{\\mu_{0}} = \\sum_{i=1}^N \\frac{(x_i - \\mu_{0})}{\\sigma_i^2} = 0$$\n",
    "\n",
    "$$\\sum_{i=1}^N \\frac{x_i}{\\sigma_i^2} = \\sum_{i=1}^N \\frac{\\mu_{0}}{\\sigma_i^2}$$\n",
    "\n",
    "$$\\mu_{0} = \\frac{\\sum_{i}^{N} (x_i/\\sigma_i^2)}{\\sum_{i}^N (1/\\sigma_i^2)}$$\n",
    "\n",
    "$$\\sigma_{\\mu} = \\left( \\sum_{i=1}^N \\frac{1}{\\sigma_i^2}\\right)^{-1/2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Properties of the Maximum Likelihood Estimators:\n",
    "\n",
    "The most important assumption while computing the estimators is that the data truly comes from the specified model class. \n",
    "\n",
    "MLEs have the following properties -\n",
    "\n",
    "- They are consistent. As the number of data points increases, they converge to the true parameter.\n",
    "- They are asymptotically normal estimators. The distribution of the parameter estimate approaches a normal distribution, center at the MLE, as the number of data points increases.\n",
    "- They achieve the best possible error given the data at hand. No other estimator can do better in terms of efficiency using each data point to reduce the total error of the estimate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Goodness of Fit:\n",
    "\n",
    "The MLE approach estimates the \"best-fit\" model parameter and gives their uncertainties, but it does not tell us how good the fit is. \n",
    "\n",
    "Using the best-fit paramters, we can compute the maximum value of the likelihood, say $L_{o}$. The goodness of fit can then be described as whether or not it is likely to have obtained $ln L_{o}$ by randomly drawing from the data. This means that the distribution of $ln L$ has to be known.\n",
    "\n",
    "For the Gaussian case,\n",
    "\n",
    "$$\\ln L = constant - \\frac{1}{2} \\sum_{i=1}^{n} \\left[\\frac{(x_i-\\mu)^2}{\\sigma^2} \\right] $$\n",
    "\n",
    "If $z_{i} = (x_i - \\mu)/ \\sigma$, then $$\\ln L = {\\rm constant} - \\frac{1}{2}\\sum_{i=1}^N z_{i}^2 = {\\rm constant} - \\frac{1}{2}\\chi^2$$ \n",
    "\n",
    "Thus, the distribution of $\\ln L$ depends on the distribution of $\\chi^2$ with $N-k$ degrees of freedom, where $k$ is the number of model parameters. \n",
    "\n",
    "The expectation value of the $\\chi^2$ distribution is $N-k$ and its standard deviation is $\\sqrt{2(N-k)}$.\n",
    "\n",
    "For a good fit, we expect that $\\chi^2$ per degree of freedom, $$\\chi_{dof}^{2} = \\frac{1}{N-k} \\sum_{i=1}^N z_{i}^2 \\approx 1$$\n",
    "\n",
    "If $(\\chi^2 - 1)$ is many times larger than $\\sqrt{2/(N-k)}$, it is likely that we are not using the correct model. We can also get overly high or low values of $\\chi_{dof}^2$, if our errors are under- or over-estimated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# An Example:\n",
    "\n",
    "Consider a case of the luminosity of a single star being measured multiple times. Our model is that of a star with no intrinsic luminosity variation. \n",
    "\n",
    "- If the model and measurement errors are consisten, $\\chi_{dof}^2$ is close to 1.\n",
    "- $\\chi_{dof}^2$ much less than 1 indicates that the errors are overestimated, while underestimating the measurement errors can lead to a high value of $\\chi_{dof}^2$. \n",
    "- $\\chi_{dof}^2$ much larger than 1 can also indicate that our model is not a description of our data. For example, if the star has an intrinsic variation, then our model will clearly not match the data.\n",
    "\n",
    "![Ivezic, Figure 4.1](http://www.astroml.org/_images/fig_chi2_eval_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MLE Applied to Gaussian Mixtures: \n",
    "\n",
    "- Data likelihood can be a complex function of many parameters that often does not admist an easy solution. Numerical methods need to be applied.\n",
    "\n",
    "- A special case of a fairly complex likelihood, but which can still be maximized using a relatively simple method is the case of Gaussian Mixtures.\n",
    "\n",
    "## Gaussian Mixture Model\n",
    "\n",
    "The likelihood of $x_i$ for a Gaussian mixture model is given by $$p(x_i|\\theta) = \\sum_{j=1}^{M} \\alpha_{j} N(\\mu_j, \\sigma_{j})$$\n",
    "\n",
    "where dependence on $x_i$ comes from a Guassian $N(\\mu_j, \\sigma_j)$. \n",
    "\n",
    "The parameters that need to be estimated for a given data now include the normalization factors for each Guassian, $\\alpha_{j}$, and its parameters $\\mu_{j}$ and $\\sigma_{j}$. It is assumed that the data have negligible uncertainties and $M$ is given. \n",
    "\n",
    "Since the likelihood of a single $x_i$ is a true pdf, $$ \\sum_{j=1}^{M} \\alpha_{j} = 1 $$\n",
    "\n",
    "The log-likelihood for the whole data set is - $$\\ln L = \\sum_{j=1}^{N} \\ln \\left[\\sum_{j=1}^{M} \\alpha_{j} N(\\mu_{j}, \\sigma_{j})\\right] $$ and needs to be maximized as a function of $k = (3M - 1)$ parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ### Class Labels and Hidden Variables - \n",
    " \n",
    "If each of the $M$ Gaussian components are interpreted as different classes, then a particular $x_i$ was generated by one and only one of the individual Gaussian components, then the index $j$ is called as a _class label_. The _hidden variable_ here is the class label $j$ responsible for generating each $x_i$. \n",
    "\n",
    "If the class label for each $x$ is known, then the maximization problem is trivial. All the data could be sorted into $M$ subsamples according to their label. Since the class labels are not known, we can only determine the probability that a datum $x_i$ belongs to a class $j$.\n",
    "\n",
    "$$ p(j|x_i) = \\frac{\\alpha_j N(\\mu_j,\\sigma_j)}{\\sum_{j=1}^{M} \\alpha_j N(\\mu_j,\\sigma_j)} \\hspace{10pt} (By \\hspace{3pt} Baye's \\hspace{3pt} Rule)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Expectation Maximixation Algorithm:\n",
    "\n",
    "The EM algorithm can be used to make the maximization of the likelihood fast and straightforward in practice. The key ingredient of the iterative EM algorithm is the assumption that the class probability is known and fixed for each iteration.\n",
    "\n",
    "The EM algorithm is not limited to Gaussian mixtures, so we can use a more generalized pdf for each component, say $p_j(x_i|\\theta)$.\n",
    "\n",
    "$$\\ln L = \\sum_{j=1}^{N} \\ln \\left[\\sum_{j=1}^{M} \\alpha_{j} p_j(x_i|\\theta)\\right] $$\n",
    "\n",
    "Taking partial derivative of $\\ln L$ w.r.t the parameter $\\theta_j$:\n",
    "\n",
    "$$ \\frac{\\partial \\ln L}{\\partial \\theta_j} = \\sum_{i=1}^{N} \\frac{\\alpha_j}{\\sum_{j=1}^M \\alpha_j p_j (x_i|\\theta)} \\left[\\frac{\\partial p_j(x_i|\\theta)}{\\partial \\theta_j} \\right] $$\n",
    "\n",
    "This can be re-written as:\n",
    "\n",
    "$$ \\frac{\\partial \\ln L}{\\partial \\theta_j} = \\sum_{i=1}^{N} \\frac{\\alpha_j p_j (x_i|\\theta)}{\\sum_{j=1}^M \\alpha_j p_j (x_i|\\theta)} \\left[\\frac{1}{p_j (x_i|\\theta)} \\frac{\\partial p_j(x_i|\\theta)}{\\partial \\theta_j} \\right] = \\sum_{i=1}^{N} p(j|x_i) \\left[\\frac{\\partial ln \\hspace{2pt} p_j(x_i|\\theta)}{\\partial \\theta_j} \\right]$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since we are assuming that the class probability will remain fixed in a given iteration, introduce $p(j|x_i) = w_{ij}$. When $p_{j}(x_i|\\theta)$ is Gaussian, then it leads to a particularly simple constraints for the model parameters.\n",
    "\n",
    "$$ \\frac{\\partial ln L}{\\partial \\theta_j} = \\sum_{i=1}^{N} w_{ij} \\frac{\\partial}{\\partial \\theta_j} \\left[ln \\sigma_j + \\frac{(x_i - \\mu_j)^2}{2 \\sigma^2} \\right] $$ where $\\theta_j$ corresponds to $\\mu_j$ or $\\sigma_j$. By maximizing individually, we get the estimators.\n",
    "\n",
    "$$ \\mu_j = \\frac{\\sum_{i=1}^{N} w_{ij}x_{i}}{\\sum_{i=1}{N} w_{ij}} $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ \\sigma_{j}^2 = \\frac{\\sum_{i=1}^{N} w_{ij} (x_i - \\mu_j)^2}{\\sum_{i=1}^{N} w_{ij}} $$\n",
    "\n",
    "From the normalization constraint, \n",
    "\n",
    "$$ \\alpha_{j} = \\frac{1}{N} \\sum_{i=1}^{N} w_{ij} $$\n",
    "\n",
    "This is the beginning of the iteration.\n",
    "\n",
    "- The algorithm is not sensitive to the initial guess of the parameter values. \n",
    "- The EM algorithm does converge.\n",
    "- However, there are a few cases when the algorithm may fail due to numerical difficulties, like when the available data are sparsely distributed, in case of outliers, or if some data points are repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ragadeepika.pucha/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:52: DeprecationWarning: Class GMM is deprecated; The class GMM is deprecated in 0.18 and will be  removed in 0.20. Use class GaussianMixture instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/ragadeepika.pucha/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The functon distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/ragadeepika.pucha/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/ragadeepika.pucha/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/ragadeepika.pucha/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.53709577],\n",
       "       [ 0.52900088]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GMM\n",
    "X = np.random.normal(size = (100, 1)) # 100 points in 1 dimension\n",
    "model = GMM(2) # two components\n",
    "model.fit(X)\n",
    "\n",
    "model.means_  # the locations of the best fit components"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Author: Jake VanderPlas\n",
    "# License: BSD\n",
    "#   The figure produced by this code is published in the textbook\n",
    "#   \"Statistics, Data Mining, and Machine Learning in Astronomy\" (2013)\n",
    "#   For more information, see http://astroML.github.com\n",
    "#   To report a bug or issue, use the following forum:\n",
    "#    https://groups.google.com/forum/#!forum/astroml-general\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.mixture import GMM\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# This function adjusts matplotlib settings for a uniform feel in the textbook.\n",
    "# Note that with usetex=True, fonts are rendered with LaTeX.  This may\n",
    "# result in an error if LaTeX is not installed on your system.  In that case,\n",
    "# you can set usetex to False.\n",
    "from astroML.plotting import setup_text_plots\n",
    "setup_text_plots(fontsize=8, usetex=False)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Set up the dataset.\n",
    "#  We'll use scikit-learn's Gaussian Mixture Model to sample\n",
    "#  data from a mixture of Gaussians.  The usual way of using\n",
    "#  this involves fitting the mixture to data: we'll see that\n",
    "#  below.  Here we'll set the internal means, covariances,\n",
    "#  and weights by-hand.\n",
    "np.random.seed(1)\n",
    "\n",
    "gmm = GMM(3, n_iter=1)\n",
    "gmm.means_ = np.array([[-1], [0], [3]])\n",
    "gmm.covars_ = np.array([[1.5], [1], [0.5]]) ** 2\n",
    "gmm.weights_ = np.array([0.3, 0.5, 0.2])\n",
    "\n",
    "X = gmm.sample(1000)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Learn the best-fit GMM models\n",
    "#  Here we'll use GMM in the standard way: the fit() method\n",
    "#  uses an Expectation-Maximization approach to find the best\n",
    "#  mixture of Gaussians for the data\n",
    "\n",
    "# fit models with 1-10 components\n",
    "N = np.arange(1, 11)\n",
    "models = [None for i in range(len(N))]\n",
    "\n",
    "for i in range(len(N)):\n",
    "    models[i] = GMM(N[i]).fit(X)\n",
    "\n",
    "# compute the AIC and the BIC\n",
    "AIC = [m.aic(X) for m in models]\n",
    "BIC = [m.bic(X) for m in models]\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Plot the results\n",
    "#  We'll use three panels:\n",
    "#   1) data + best-fit mixture\n",
    "#   2) AIC and BIC vs number of components\n",
    "#   3) probability that a point came from each component\n",
    "\n",
    "fig = plt.figure(figsize=(5, 1.7))\n",
    "fig.subplots_adjust(left=0.12, right=0.97,\n",
    "                    bottom=0.21, top=0.9, wspace=0.5)\n",
    "\n",
    "\n",
    "# plot 1: data + best-fit mixture\n",
    "ax = fig.add_subplot(131)\n",
    "M_best = models[np.argmin(AIC)]\n",
    "\n",
    "x = np.linspace(-6, 6, 1000)\n",
    "logprob, responsibilities = M_best.eval(x)\n",
    "print (responsibilities)\n",
    "pdf = np.exp(logprob)\n",
    "pdf_individual = responsibilities * pdf[:, np.newaxis]\n",
    "\n",
    "ax.hist(X, 30, normed=True, histtype='stepfilled', alpha=0.4)\n",
    "ax.plot(x, pdf, '-k')\n",
    "ax.plot(x, pdf_individual, '--k')\n",
    "ax.text(0.04, 0.96, \"Best-fit Mixture\",\n",
    "        ha='left', va='top', transform=ax.transAxes)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$p(x)$')\n",
    "\n",
    "\n",
    "# plot 2: AIC and BIC\n",
    "ax = fig.add_subplot(132)\n",
    "ax.plot(N, AIC, '-k', label='AIC')\n",
    "ax.plot(N, BIC, '--k', label='BIC')\n",
    "ax.set_xlabel('n. components')\n",
    "ax.set_ylabel('information criterion')\n",
    "ax.legend(loc=2)\n",
    "\n",
    "\n",
    "# plot 3: posterior probabilities for each component\n",
    "ax = fig.add_subplot(133)\n",
    "\n",
    "p = M_best.predict_proba(x)\n",
    "p = p[:, (1, 0, 2)]  # rearrange order so the plot looks better\n",
    "p = p.cumsum(1).T\n",
    "\n",
    "ax.fill_between(x, 0, p[0], color='gray', alpha=0.3)\n",
    "ax.fill_between(x, p[0], p[1], color='gray', alpha=0.5)\n",
    "ax.fill_between(x, p[1], 1, color='gray', alpha=0.7)\n",
    "ax.set_xlim(-6, 6)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel(r'$p({\\rm class}|x)$')\n",
    "\n",
    "ax.text(-5, 0.3, 'class 1', rotation='vertical')\n",
    "ax.text(0, 0.5, 'class 2', rotation='vertical')\n",
    "ax.text(3, 0.3, 'class 3', rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Ivezic, Figure 4.1](http://www.astroml.org/_images/fig_GMM_1D_1.png)\n",
    "\n",
    "- Example of a one-dimensional Gaussian Mixture Model with three components. \n",
    "- Left Panel: Histogram of the data, along with the best-fit model for a mixture of three components.\n",
    "- Center Panel: Model Selection Criteria - AIC and BIC (Section 4.3.2).\n",
    "- Right Panel - Probability that a given point is drawn from each class as a function of its position. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assumptions used in the EM algorithm -\n",
    "\n",
    "- The number of classes, M, is known.\n",
    "- The measurement erros for $\\{x_i\\}$ are negligible compared to the smallest component width, $\\sigma_j$.\n",
    "- The mixture models are Gaussian.\n",
    "\n",
    "The EM algorithm can be extended to not include these assumptions. Further explanation - Section 4.4.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Next Steps:\n",
    "\n",
    "- Confidence Intervals - Bootstrap and Jackknife (Section 4.5).\n",
    "- Hypothesis Testing (Section 4.6)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
